{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-05-model-validation-in-python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxq_4lSN5Bef"
      },
      "source": [
        "# Model Validation in Python\n",
        "## 1. Basic Modeling in scikit-learn\n",
        "## 2. Validation Basics\n",
        "## 3. Cross Validation\n",
        "## 4. Selecting the best model with Hyperparameter tuning."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKLcOpqA5kel"
      },
      "source": [
        "## 1. Basic Modeling in scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ERN8yP95jdM"
      },
      "source": [
        "# Introduction to model validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQc2Z__0SPhF"
      },
      "source": [
        "**Modeling steps**\n",
        "\n",
        "The process of using scikit-learn to create and test models has four steps, and you will use these four steps throughout this course.\n",
        "\n",
        "Which of the following is NOT a valid method in the four-step scikit-learn model validation framework?\n",
        "\n",
        "**Possible Answers**\n",
        "\n",
        "- [ ] .predict()\n",
        "- [ ] .fit()\n",
        "- [x] .validate()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chXhmB65SceT",
        "outputId": "a18707cf-3371-4ef0-add8-799742169199"
      },
      "source": [
        "# Seen vs. unseen data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/candy-data.csv'\n",
        "candy = pd.read_csv(filename)\n",
        "X = candy[['chocolate', 'fruity', 'caramel', 'peanutyalmondy',\n",
        "       'nougat', 'crispedricewafer', 'hard', 'bar', 'pluribus', 'sugarpercent',\n",
        "       'pricepercent']]\n",
        "y = candy['winpercent']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.41)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error as mae\n",
        "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
        "           oob_score=False, random_state=1111, verbose=0, warm_start=False)\n",
        "\n",
        "# The model is fit using X_train and y_train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Create vectors of predictions\n",
        "train_predictions = model.predict(X_train)\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Train/Test Errors\n",
        "train_error = mae(y_true=y_train, y_pred=train_predictions)\n",
        "test_error = mae(y_true=y_test, y_pred=test_predictions)\n",
        "\n",
        "# Print the accuracy for seen and unseen data\n",
        "print(\"Model error on seen data: {0:.2f}.\".format(train_error))\n",
        "print(\"Model error on unseen data: {0:.2f}.\".format(test_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model error on seen data: 25.02.\n",
            "Model error on unseen data: 147.47.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoZqyPyFTxWe",
        "outputId": "19321d82-a155-4751-bc0b-739838afe935"
      },
      "source": [
        "# Regression models\n",
        "\n",
        "# Set parameters and fit a model\n",
        "\n",
        "rfr = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,\n",
        "           max_features='auto', max_leaf_nodes=None,\n",
        "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "           min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
        "           oob_score=False, random_state=1111, verbose=0, warm_start=False)\n",
        "\n",
        "# Set the number of trees\n",
        "rfr.n_estimators = 100\n",
        "\n",
        "# Add a maximum depth\n",
        "rfr.max_depth = 6\n",
        "\n",
        "# Set the random state\n",
        "rfr.random_state = 1111\n",
        "\n",
        "# Fit the model\n",
        "rfr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
              "                      max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
              "                      max_samples=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
              "                      random_state=1111, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL0HbwdgTzlq",
        "outputId": "0875c491-0eed-4738-ecdd-fa6abfc0fb82"
      },
      "source": [
        "# Feature importances\n",
        "\n",
        "# Fit the model using X and y\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print how important each column is to the model\n",
        "for i, item in enumerate(rfr.feature_importances_):\n",
        "      # Use i and item to print out the feature importance of each column\n",
        "    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chocolate: 0.27\n",
            "fruity: 0.02\n",
            "caramel: 0.01\n",
            "peanutyalmondy: 0.09\n",
            "nougat: 0.01\n",
            "crispedricewafer: 0.04\n",
            "hard: 0.03\n",
            "bar: 0.05\n",
            "pluribus: 0.03\n",
            "sugarpercent: 0.17\n",
            "pricepercent: 0.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdQOdwI1UKtT",
        "outputId": "d4af2d54-a5a2-43ff-9da4-884fddb0c110"
      },
      "source": [
        "# Classification models\n",
        "\n",
        "# Classification predictions\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/tic-tac-toe.csv'\n",
        "tic_tac_toe = pd.read_csv(filename)\n",
        "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "X = tic_tac_toe.drop('Class', axis = 1)\n",
        "X = pd.get_dummies(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
        "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
        "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
        "            oob_score=False, random_state=1111, verbose=0,\n",
        "            warm_start=False)\n",
        "\n",
        "# Fit the rfc model. \n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create arrays of predictions\n",
        "classification_predictions = rfc.predict(X_test)\n",
        "probability_predictions = rfc.predict_proba(X_test)\n",
        "\n",
        "# Print out count of binary predictions\n",
        "print(pd.Series(classification_predictions).value_counts())\n",
        "\n",
        "# Print the first value from probability_predictions\n",
        "print('The first predicted probabilities are: {}'.format(probability_predictions[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    547\n",
            "0    220\n",
            "dtype: int64\n",
            "The first predicted probabilities are: [0.32868978 0.67131022]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh1mqWBVUjxp",
        "outputId": "bafe37b5-3d8f-47d6-b13a-c5a6a5baa968"
      },
      "source": [
        "# Reusing model parameters\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
        "\n",
        "# Print the classification model\n",
        "print(rfc)\n",
        "\n",
        "# Print the classification model's random state parameter\n",
        "print('The random state is: {}'.format(rfc.random_state))\n",
        "\n",
        "# Print all parameters\n",
        "print('Printing the parameters dictionary: {}'.format(rfc.get_params()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=6, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
            "                       n_jobs=None, oob_score=False, random_state=1111,\n",
            "                       verbose=0, warm_start=False)\n",
            "The random state is: 1111\n",
            "Printing the parameters dictionary: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSobSoNtUtbW",
        "outputId": "a36bc8c0-5b8b-447d-a94f-87a574762a31"
      },
      "source": [
        "# Random forest classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a random forest classifier\n",
        "rfc = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=1111)\n",
        "\n",
        "# Fit rfc using X_train and y_train\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Create predictions on X_test\n",
        "predictions = rfc.predict(X_test)\n",
        "print(predictions[0:5])\n",
        "\n",
        "# Print model accuracy using score() and the testing data\n",
        "print(rfc.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 1 1]\n",
            "0.8226857887874837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9a2hE92U7_C"
      },
      "source": [
        "## 2. Validation Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_AkJ-FsU8qK"
      },
      "source": [
        "# Creating train, test, and validation datasets\n",
        "\n",
        "# Create one holdout set\n",
        "\n",
        "# Create dummy variables using pandas\n",
        "X = pd.get_dummies(tic_tac_toe.iloc[:,0:9])\n",
        "y = tic_tac_toe.iloc[:, 9]\n",
        "\n",
        "# Create training and testing datasets. Use 10% for the test set\n",
        "X_train, X_test, y_train, y_test  =train_test_split(X, y, test_size = 0.1, random_state=1111)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzFNiWnKVQMX"
      },
      "source": [
        "# Create two holdout sets\n",
        "\n",
        "# Create temporary training and final testing datasets\n",
        "X_temp, X_test, y_temp, y_test  =\\\n",
        "    train_test_split(X, y, test_size = 0.2, random_state=1111)\n",
        "\n",
        "# Create the final training and validation datasets\n",
        "X_train, X_val, y_train, y_val =\\\n",
        "    train_test_split(X_temp, y_temp, test_size = 0.25, random_state=1111)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osYGWpmDVZkY"
      },
      "source": [
        "**Why use holdout sets**\n",
        "\n",
        "It is important to understand when you would use three datasets (training, validation, and testing) instead of two (training and testing). There is no point in creating an additional dataset split if you are not going to use it.\n",
        "\n",
        "When should you consider using training, validation, and testing datasets?\n",
        "\n",
        "**Possible Answers**\n",
        "\n",
        "- [ ] When there is a lot of data. Splitting into three sets helps speed up modeling.\n",
        "- [x] When testing parameters, tuning hyper-parameters, or anytime you are frequently evaluating model performance.\n",
        "- [ ] Only when you are running regression and not classification models.\n",
        "- [ ] Only when you are running classification and not regression models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAdTXuVXVXDe",
        "outputId": "eecfe9ea-7b59-4ce2-948f-ec47ccd09f0d"
      },
      "source": [
        "# Accuracy metrics: regression models\n",
        "\n",
        "# Mean absolute error\n",
        "\n",
        "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15, 72, 58,\n",
        "       60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])\n",
        "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20, 67, 61,\n",
        "       55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Manually calculate the MAE\n",
        "n = len(predictions)\n",
        "mae_one = sum(abs(y_test - predictions)) / n\n",
        "print('With a manual calculation, the error is {}'.format(mae_one))\n",
        "\n",
        "# Use scikit-learn to calculate the MAE\n",
        "mae_two = mean_absolute_error(y_test, predictions)\n",
        "print('Using scikit-lean, the error is {}'.format(mae_two))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With a manual calculation, the error is 5.9\n",
            "Using scikit-lean, the error is 5.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DojjYiQuXjFM",
        "outputId": "545b9332-86c0-4529-fb82-8a3e1b4adb52"
      },
      "source": [
        "# Mean squared error\n",
        "\n",
        "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15, 72, 58,\n",
        "       60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])\n",
        "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20, 67, 61,\n",
        "       55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "n = len(predictions)\n",
        "# Finish the manual calculation of the MSE\n",
        "mse_one = sum(abs(y_test - predictions)**2) / n\n",
        "print('With a manual calculation, the error is {}'.format(mse_one))\n",
        "\n",
        "# Use the scikit-learn function to calculate MSE\n",
        "mse_two = mean_squared_error(y_test, predictions)\n",
        "print('Using scikit-lean, the error is {}'.format(mse_two))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With a manual calculation, the error is 49.1\n",
            "Using scikit-lean, the error is 49.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnId7T2bXyev",
        "outputId": "18fc3737-df60-41ff-838c-8acd0a7135f0"
      },
      "source": [
        "# Performance on data subsets\n",
        "\n",
        "y_test = np.array([53, 51, 51, 49, 43, 42, 42, 41, 41, 37, 36, 31, 29, 28, 20, 67, 61, 55, 51, 51, 47, 43, 41, 40, 34, 33, 32, 31, 26, 24])\n",
        "predictions = np.array([60, 62, 42, 42, 30, 50, 52, 42, 44, 35, 30, 30, 35, 40, 15, 72, 58, 60, 40, 42, 45, 46, 40, 35, 25, 40, 20, 34, 25, 24])\n",
        "labels = np.array(['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W', 'W','W', 'W', 'W', 'W'])\n",
        "\n",
        "# Find the East conference teams\n",
        "east_teams = labels == \"E\"\n",
        "\n",
        "# Create arrays for the true and predicted values\n",
        "true_east = y_test[east_teams]\n",
        "preds_east = predictions[east_teams]\n",
        "\n",
        "# Print the accuracy metrics\n",
        "print('The MAE for East teams is {}'.format(\n",
        "    mae(true_east, preds_east)))\n",
        "\n",
        "# Print the West accuracy\n",
        "west_error = 5.01\n",
        "print('The MAE for West conference is {}'.format(west_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MAE for East teams is 59.266666666666666\n",
            "The MAE for West conference is 5.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM89CAY7ZMiD",
        "outputId": "98048902-179b-4e66-dac0-c9955eb9d77c"
      },
      "source": [
        "# Classification metrics\n",
        "\n",
        "# Confusion matrices\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = (324+491) / (953)\n",
        "print(\"The overall accuracy is {0: 0.2f}\".format(accuracy))\n",
        "\n",
        "# Calculate and print the precision\n",
        "precision = (491) / (491 + 15)\n",
        "print(\"The precision is {0: 0.2f}\".format(precision))\n",
        "\n",
        "# Calculate and print the recall\n",
        "recall = (491) / (491+123)\n",
        "print(\"The recall is {0: 0.2f}\".format(recall))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The overall accuracy is  0.86\n",
            "The precision is  0.97\n",
            "The recall is  0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wndmYQzZZekP",
        "outputId": "3d9e3186-b46f-47fd-858d-ea08f9856158"
      },
      "source": [
        "# Confusion matrices, again\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/tic-tac-toe.csv'\n",
        "tic_tac_toe = pd.read_csv(filename)\n",
        "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "X = tic_tac_toe.drop('Class', axis = 1)\n",
        "X = pd.get_dummies(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create predictions\n",
        "test_predictions = rfc.predict(X_test)\n",
        "\n",
        "# Create and print the confusion matrix\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "print(cm)\n",
        "\n",
        "# Print the true positives (actual 1s that were predicted 1s)\n",
        "print(\"The number of true positives is: {}\".format(cm[1, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[195  67]\n",
            " [ 39 466]]\n",
            "The number of true positives is: 466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBGn6HDMam6Y",
        "outputId": "565305bc-e166-492f-f5b3-22ee47c29eba"
      },
      "source": [
        "# Precision vs. recall\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "test_predictions = rfc.predict(X_test)\n",
        "\n",
        "# Create precision or recall score based on the metric you imported\n",
        "score = precision_score(y_test, test_predictions)\n",
        "\n",
        "# Print the final result\n",
        "print(\"The precision value is {0:.2f}\".format(score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The precision value is 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp3a3q38asRg",
        "outputId": "058ec8cb-dfa3-4556-da21-bfd3349ba414"
      },
      "source": [
        "# The bias-variance tradeoff\n",
        "\n",
        "# Error due to under/over-fitting\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/candy-data.csv'\n",
        "candy = pd.read_csv(filename)\n",
        "X = candy[['chocolate', 'fruity', 'caramel', 'peanutyalmondy',\n",
        "       'nougat', 'crispedricewafer', 'hard', 'bar', 'pluribus', 'sugarpercent',\n",
        "       'pricepercent']]\n",
        "y = candy['winpercent']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.41)\n",
        "\n",
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25,\n",
        "                            random_state=1111,\n",
        "                            max_features=2)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print the training and testing accuracies \n",
        "print('The training error is {0:.2f}'.format(\n",
        "  mae(y_train, rfr.predict(X_train))))\n",
        "print('The testing error is {0:.2f}'.format(\n",
        "  mae(y_test, rfr.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training error is 24.17\n",
            "The testing error is 128.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNTVRMsZbUHe",
        "outputId": "f45a1d27-f52a-4bc0-d4a8-cfe907bd8304"
      },
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25,\n",
        "                            random_state=1111,\n",
        "                            max_features=11)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print the training and testing accuracies \n",
        "print('The training error is {0:.2f}'.format(\n",
        "  mae(y_train, rfr.predict(X_train))))\n",
        "print('The testing error is {0:.2f}'.format(\n",
        "  mae(y_test, rfr.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training error is 27.71\n",
            "The testing error is 107.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOEJSD2_bRN1",
        "outputId": "003ced88-d5d8-4e2f-fb0d-2c635130c246"
      },
      "source": [
        "# Update the rfr model\n",
        "rfr = RandomForestRegressor(n_estimators=25,\n",
        "                            random_state=1111,\n",
        "                            max_features=4)\n",
        "rfr.fit(X_train, y_train)\n",
        "\n",
        "# Print the training and testing accuracies \n",
        "print('The training error is {0:.2f}'.format(\n",
        "  mae(y_train, rfr.predict(X_train))))\n",
        "print('The testing error is {0:.2f}'.format(\n",
        "  mae(y_test, rfr.predict(X_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training error is 25.25\n",
            "The testing error is 121.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db_lGmWWchAt",
        "outputId": "d29157ff-a05c-4a4b-8902-713468e6d5eb"
      },
      "source": [
        "# Am I underfitting?\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/tic-tac-toe.csv'\n",
        "tic_tac_toe = pd.read_csv(filename)\n",
        "y = tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "X = tic_tac_toe.drop('Class', axis = 1)\n",
        "X = pd.get_dummies(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.8)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_scores, train_scores = [], []\n",
        "for i in [1, 2, 3, 4, 5, 10, 20, 50]:\n",
        "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
        "    rfc.fit(X_train, y_train)\n",
        "    # Create predictions for the X_train and X_test datasets.\n",
        "    train_predictions = rfc.predict(X_train)\n",
        "    test_predictions = rfc.predict(X_test)\n",
        "    # Append the accuracy score for the test and train predictions.\n",
        "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
        "    test_scores.append(round(accuracy_score(y_test, test_predictions), 2))\n",
        "# Print the train and test scores.\n",
        "print(\"The training scores were: {}\".format(train_scores))\n",
        "print(\"The testing scores were: {}\".format(test_scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training scores were: [0.94, 0.93, 0.95, 0.96, 0.97, 1.0, 1.0, 1.0]\n",
            "The testing scores were: [0.68, 0.65, 0.74, 0.73, 0.77, 0.77, 0.8, 0.82]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwybr-IkczMv"
      },
      "source": [
        "## 3. Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2xTqdBocz72",
        "outputId": "1349bc04-c475-4a8a-8876-e5b2f6686ac6"
      },
      "source": [
        "# Two samples\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/tic-tac-toe.csv'\n",
        "tic_tac_toe = pd.read_csv(filename)\n",
        "\n",
        "# Create two different samples of 200 observations \n",
        "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
        "sample2 = tic_tac_toe.sample(200, random_state=1171)\n",
        "\n",
        "# Print the number of common observations \n",
        "print(len([index for index in sample1.index if index in sample2.index]))\n",
        "\n",
        "# Print the number of observations in the Class column for both samples \n",
        "print(sample1['Class'].value_counts())\n",
        "print(sample2['Class'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "positive    134\n",
            "negative     66\n",
            "Name: Class, dtype: int64\n",
            "positive    123\n",
            "negative     77\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DitaOkBodKNr"
      },
      "source": [
        "**Potential problems**\n",
        "\n",
        "Which of the following statements are TRUE regarding potential problems with holdout samples:\n",
        "\n",
        "- A: Using different data splitting methods may lead to varying data in the final holdout samples.\n",
        "- B: If you have limited data, your holdout accuracy may be misleading.\n",
        "- C: There are no problems. Creating a single train and test sample is the only way to validate models.\n",
        "- D: You shouldn't use holdout samples with limited data because you are limiting the potential training data.\n",
        "\n",
        "**Possible Answers**\n",
        "\n",
        "- [ ] A & D\n",
        "- [ ] C & D\n",
        "- [x] A & B\n",
        "- [ ] A, B, & D\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t22wFYBFdYDF",
        "outputId": "1a69a638-560c-429f-a23c-1514ecbcec7b"
      },
      "source": [
        "# Cross-validation\n",
        "\n",
        "# scikit-learn's KFold()\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/candy-data.csv'\n",
        "candy = pd.read_csv(filename)\n",
        "X = candy[['chocolate', 'fruity', 'caramel', 'peanutyalmondy',\n",
        "       'nougat', 'crispedricewafer', 'hard', 'bar', 'pluribus', 'sugarpercent',\n",
        "       'pricepercent']].values\n",
        "y = candy['winpercent'].values\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Use KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
        "\n",
        "# Create splits\n",
        "splits = kf.split(X)\n",
        "\n",
        "# Print the number of indices\n",
        "for train_index, val_index in splits:\n",
        "    print(\"Number of training indices: %s\" % len(train_index))\n",
        "    print(\"Number of validation indices: %s\" % len(val_index))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n",
            "Number of training indices: 68\n",
            "Number of validation indices: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbzuhpnIdrqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb532e69-c5fa-41b3-f101-6f407bcf069d"
      },
      "source": [
        "# Using KFold indices\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
        "splits = kf.split(X)\n",
        "\n",
        "# Access the training and validation indices of splits\n",
        "for train_index, val_index in splits:\n",
        "    # Setup the training and validation data\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_val, y_val = X[val_index], y[val_index]\n",
        "    # Fit the random forest model\n",
        "    rfc.fit(X_train, y_train)\n",
        "    # Make predictions, and print the accuracy\n",
        "    predictions = rfc.predict(X_val)\n",
        "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Split accuracy: 151.5028145199104\n",
            "Split accuracy: 173.4624060357644\n",
            "Split accuracy: 132.7340977072911\n",
            "Split accuracy: 81.50364942339418\n",
            "Split accuracy: 217.17904656079338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YebJg0rktZ2"
      },
      "source": [
        "# sklearn's cross_val_score()\n",
        "\n",
        "# scikit-learn's methods\n",
        "\n",
        "# Load the cross-validation method\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the random forest regression model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load the mean squared error method\n",
        "# Load the function for creating a scorer\n",
        "from sklearn.metrics import mean_squared_error, make_scorer"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiAy9by_k1i0",
        "outputId": "ef272b5c-164c-4a5a-c7ca-6c265655def2"
      },
      "source": [
        "# Implement cross_val_score()\n",
        "\n",
        "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
        "mse = make_scorer(mean_squared_error)\n",
        "\n",
        "# Set up cross_val_score\n",
        "cv = cross_val_score(estimator=rfc,\n",
        "                     X=X_train,\n",
        "                     y=y_train,\n",
        "                     cv=10,\n",
        "                     scoring=mse)\n",
        "\n",
        "# Print the mean error\n",
        "print(cv.mean())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130.91371947185584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0omF_TSZk8x3"
      },
      "source": [
        "# Leave-one-out-cross-validation (LOOCV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4baWxYErlAsl"
      },
      "source": [
        "**When to use LOOCV**\n",
        "\n",
        "Which of the following are reasons you might NOT run LOOCV on the provided X dataset? The X data has been loaded for you to explore as you see fit.\n",
        "\n",
        "- A: The X dataset has 122,624 data points, which might be computationally expensive and slow.\n",
        "- B: You cannot run LOOCV on classification problems.\n",
        "- C: You want to test different values for 15 different parameters\n",
        "\n",
        "**Possible Answers**\n",
        "\n",
        "- [ ] A & B\n",
        "- [ ] B & C\n",
        "- [x] A & C\n",
        "- [ ] A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcv_FLUylMy0",
        "outputId": "9216f50d-0336-44f1-9ece-8e66505b61cc"
      },
      "source": [
        "# Leave-one-out-cross-validation\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, make_scorer\n",
        "\n",
        "# Create scorer\n",
        "mae_scorer = make_scorer(mean_absolute_error)\n",
        "\n",
        "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n",
        "\n",
        "# Implement LOOCV\n",
        "scores = cross_val_score(rfr, X=X, y=y, cv=85, scoring=mae_scorer)\n",
        "\n",
        "# Print the mean and standard deviation\n",
        "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
        "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean of the errors is: 9.464989603398694.\n",
            "The standard deviation of the errors is: 7.265762094853885.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTBhtt3AlYJ9"
      },
      "source": [
        "## 4. Selecting the best model with Hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtuGjDMClY6n",
        "outputId": "8b3a8274-c8fa-4eb0-e038-892d4c410e35"
      },
      "source": [
        "# Creating Hyperparameters\n",
        "\n",
        "# Review the parameters of rfr\n",
        "print(rfr.get_params())\n",
        "\n",
        "# Maximum Depth\n",
        "max_depth = [4, 8, 12]\n",
        "\n",
        "# Minimum samples for a split\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# Max features \n",
        "max_features = [4, 6, 8, 10]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 15, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Aj190dlkj1",
        "outputId": "f24271ee-53b8-4c5a-9548-d9dc4c672fbf"
      },
      "source": [
        "# Running a model using ranges\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import random\n",
        "\n",
        "# Fill in rfr using your variables\n",
        "rfr = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=random.choice(max_depth),\n",
        "    min_samples_split=random.choice(min_samples_split),\n",
        "    max_features=random.choice(max_features))\n",
        "\n",
        "# Print out the parameters\n",
        "print(rfr.get_params())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 4, 'max_features': 6, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Iwb-dYltQU"
      },
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "# Finish the dictionary by adding the max_depth parameter\n",
        "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
        "              \"max_features\": [2, 4, 6, 8, 10],\n",
        "              \"min_samples_split\": [2, 4, 8, 16]}\n",
        "\n",
        "# Create a random forest regression model\n",
        "rfr = RandomForestRegressor(n_estimators =10, random_state=1111)\n",
        "\n",
        "# Create a scorer to use (use the mean squared error)\n",
        "scorer = make_scorer(mean_squared_error)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHh_ofk2l5Mb"
      },
      "source": [
        "# Implementing RandomizedSearchCV\n",
        "\n",
        "# Import the method for random search\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Build a random search using param_dist, rfr, and scorer\n",
        "random_search =\\\n",
        "    RandomizedSearchCV(\n",
        "        estimator=rfr,\n",
        "        param_distributions=param_dist,\n",
        "        n_iter=10,\n",
        "        cv=5,\n",
        "        scoring=scorer)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeH5lgyymABM"
      },
      "source": [
        "# Selecting your final model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAiIU77qmFrb"
      },
      "source": [
        "**Best classification accuracy**\n",
        "\n",
        "You are in a competition at work to build the best model for predicting the winner of a Tic-Tac-Toe game. You already ran a random search and saved the results of the most accurate model to rs.\n",
        "\n",
        "Which parameter set produces the best classification accuracy?\n",
        "\n",
        "**Possible Answers**\n",
        "\n",
        "- [ ] `{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 10`\n",
        "- [ ] `{'max_depth': 2, 'min_samples_split': 4, 'n_estimators': 10}`\n",
        "- [x] `{'max_depth': 12, 'min_samples_split': 4, 'n_estimators': 20}`\n",
        "- [ ] `{'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 50}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbCfjbwomTc8"
      },
      "source": [
        "# Selecting the best precision model\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/chesterheng/ai-for-industry/main/datasets/tic-tac-toe.csv'\n",
        "tic_tac_toe = pd.read_csv(filename)\n",
        "y = list(tic_tac_toe['Class'].apply(lambda x: 1 if x == 'positive' else 0))\n",
        "X = tic_tac_toe.drop('Class', axis = 1)\n",
        "X = pd.get_dummies(X).values\n",
        "\n",
        "from sklearn.metrics import precision_score, make_scorer\n",
        "\n",
        "# # Create a precision scorer\n",
        "# precision = make_scorer(precision_score)\n",
        "\n",
        "# # Finalize the random search\n",
        "# rs = RandomizedSearchCV(\n",
        "#   estimator=rfc, param_distributions=param_dist,\n",
        "#   scoring = precision,\n",
        "#   cv=5, n_iter=10, random_state=1111)\n",
        "# rs.fit(X, y)\n",
        "\n",
        "# # print the mean test scores:\n",
        "# print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
        "# # print the best model score:\n",
        "# print('The best accuracy for a single model was: {}'.format(rs.best_score_))"
      ],
      "execution_count": 108,
      "outputs": []
    }
  ]
}